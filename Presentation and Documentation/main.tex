\documentclass[12pt,a4paper]{article}

% Essential packages for Overleaf compatibility
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage{amsmath,amsfonts,amssymb}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{url}
\usepackage{hyperref}
\usepackage{float}
\usepackage{array}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{setspace}
\usepackage{caption}
\usepackage{subcaption}

% Page setup
\pagestyle{fancy}
\fancyhf{}
\rhead{\thepage}
\lhead{Autonomous Line-Following Robot}
\renewcommand{\headrulewidth}{0.4pt}

% Line spacing
\onehalfspacing

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    citecolor=blue,
}

% Code listing configuration for Arduino/C++
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{arduinostyle}{
    language=C++,
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    frame=single,
    rulecolor=\color{black}
}

\lstset{style=arduinostyle}

% Custom commands
\newcommand{\code}[1]{\texttt{#1}}

% Title information
\title{
    \vspace{-2cm}
    \LARGE\textbf{Autonomous Line-Following Robot with Advanced Obstacle Avoidance Capabilities}\\
    \vspace{0.5cm}
    \Large Systems Engineering and Prototyping\\
    \large B.Eng. Electronic Engineering\\
    \vspace{0.3cm}
    \normalsize Hochschule Hamm-Lippstadt, Lippstadt, Germany
}

\author{
    \begin{tabular}{c}
        \textbf{Md Zulkar Nain Sayeed}\\
        \small\texttt{md-zulkar-nain.sayeed@stud.hshl.de}\\[0.3cm]
        \textbf{Md Helal Uddin}\\
        \small\texttt{md-helal.uddin@stud.hshl.de}\\[0.3cm]
        \textbf{Md Arman Zaid Efty}\\
        \small\texttt{md-arman-zaid.efty@stud.hshl.de}
    \end{tabular}
}

\date{\today}

\begin{document}

\maketitle
\thispagestyle{empty}

\vspace{1cm}

\begin{abstract}
\noindent This paper presents the design and implementation of an autonomous line-following robot with advanced obstacle avoidance capabilities. The system integrates multiple sensors including infrared sensors for line detection, ultrasonic sensors for obstacle detection, and color sensors for intelligent obstacle classification. The robot demonstrates adaptive behavior based on color recognition, implementing different strategies for red and blue obstacles. The Arduino Uno-based system successfully combines real-time sensor processing with motor control algorithms to achieve autonomous navigation.

\vspace{0.5cm}
\noindent\textbf{Keywords:} Autonomous robotics, Line following, Obstacle avoidance, Color detection, Arduino, Sensor fusion
\end{abstract}

\newpage
\tableofcontents
\newpage

\section{Introduction}

Autonomous mobile robots have gained significant importance in various applications ranging from industrial automation to educational robotics. Line-following robots represent a fundamental class of autonomous vehicles that navigate by following predetermined paths marked by lines on the ground. This project extends the basic line-following concept by incorporating intelligent obstacle avoidance and color-based decision making.

The developed robot system combines three primary functionalities: precise line following using infrared sensors, obstacle detection through ultrasonic sensing, and color-based obstacle classification for adaptive behavior. The integration of these capabilities demonstrates advanced autonomous navigation principles applicable to real-world robotic systems.

The main contributions of this work include:
\begin{itemize}
    \item Design and implementation of a multi-sensor autonomous navigation system
    \item Development of adaptive obstacle avoidance strategies based on color classification
    \item Integration of real-time sensor processing with motor control algorithms
    \item Validation of system performance through comprehensive testing
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{images/robot_introduction.jpg}
    \caption{Autonomous Line-Following Robot with Obstacle Avoidance System}
    \label{fig:robot_introduction}
\end{figure}

\section{System Design and Engineering}

\subsection{System Architecture}

The robot system follows a modular architecture with distinct functional blocks designed for optimal performance and maintainability:

\begin{itemize}
    \item \textbf{Sensor Subsystem}: Infrared sensors for line detection, ultrasonic sensor for distance measurement, and color sensor for object classification
    \item \textbf{Control Subsystem}: Arduino Uno microcontroller serving as the central processing unit
    \item \textbf{Actuation Subsystem}: Motor controller and DC motors for movement
    \item \textbf{Power Management}: Battery system with switch control
\end{itemize}

The modular design ensures that each subsystem can be independently tested, maintained, and upgraded without affecting the overall system functionality.

\subsection{Requirements Analysis}

The system requirements were systematically analyzed and categorized into functional and non-functional requirements to ensure comprehensive coverage of system capabilities.

\subsubsection{Functional Requirements}

The functional requirements define what the system must do:

\begin{itemize}
    \item \textbf{REQ-001-1}: Autonomous operation with synchronized component integration
    \item \textbf{REQ-001-2}: Motion control based on IR and ultrasonic sensor readings
    \item \textbf{REQ-002-1}: Line following capability using infrared sensors
    \item \textbf{REQ-002-2}: Obstacle detection within 15cm range
    \item \textbf{REQ-002-3}: Color detection and classification for adaptive behavior
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/functional_requirements.png}
    \caption{Functional Requirements System Overview}
    \label{fig:functional_requirements}
\end{figure}

\subsubsection{Non-Functional Requirements}

The non-functional requirements specify how well the system must perform:

\begin{itemize}
    \item \textbf{NFR-001}: Collision avoidance within 1 second response time
    \item \textbf{NFR-002}: Real-time response to events within 100 milliseconds
    \item \textbf{NFR-003}: Energy efficiency with automatic power management
    \item \textbf{NFR-004}: Robust operation in varying lighting conditions
    \item \textbf{NFR-005}: Adaptive obstacle handling with recovery time under 2 seconds
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/non_functional_requirements.png}
    \caption{Non-Functional Requirements Performance Metrics}
    \label{fig:non_functional_requirements}
\end{figure}

\section{Prototyping and Design}

\subsection{Electronic Components}

The robot incorporates carefully selected components to achieve optimal performance:

\begin{table}[H]
\centering
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Component} & \textbf{Model/Type} & \textbf{Function} \\
\midrule
Microcontroller & Arduino Uno & Central processing and control \\
IR Sensors & 2× Infrared sensors & Line detection and following \\
Distance Sensor & HC-SR04 Ultrasonic & Obstacle detection \\
Color Sensor & TCS3200 & Object color classification \\
Motor Driver & L298N H-Bridge & Motor speed and direction control \\
Motors & 2× DC Geared Motors & Robot locomotion \\
Power Supply & Battery Pack & System power \\
Chassis & Custom Frame & Component mounting \\
\bottomrule
\end{tabular}
\caption{System Components Overview}
\label{tab:components}
\end{table}

\subsection{Hardware Assembly}

The hardware assembly process involved strategic placement of components for optimal sensor performance and mechanical stability:

\begin{itemize}
    \item \textbf{IR sensors}: Positioned at the front edge for optimal line detection
    \item \textbf{Ultrasonic sensor}: Mounted centrally for forward obstacle detection
    \item \textbf{Color sensor}: Positioned for ground-level object analysis
    \item \textbf{Motors}: Configured for differential drive steering
    \item \textbf{Arduino}: Centrally mounted for easy access and cable management
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{images/hardware_assembly.jpg}
    \caption{Complete Hardware Assembly and Component Layout}
    \label{fig:hardware_assembly}
\end{figure}

\subsection{Pin Configuration and Connections}

The pin configuration was designed to minimize interference and ensure reliable signal transmission:

\begin{table}[H]
\centering
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Component} & \textbf{Arduino Pins} \\
\midrule
Motor Control (L298N) & Digital Pins 2-6, PWM Pin 9 \\
Ultrasonic Sensor & Digital Pins 7 (Trigger), 8 (Echo) \\
IR Sensors & Analog Pins A0 (Left), A1 (Right) \\
Color Sensor (TCS3200) & Pins A2-A5, Digital Pins 11, 13 \\
\bottomrule
\end{tabular}
\caption{Pin Configuration Summary}
\label{tab:pins}
\end{table}

\section{Circuit Design}

The circuit design integrates all sensors and actuators through the Arduino Uno microcontroller, ensuring proper power distribution and signal integrity. The L298N motor driver provides isolated power to the drive motors while maintaining communication with the Arduino for speed and direction control.

Key design considerations include:
\begin{itemize}
    \item Proper grounding to minimize noise interference
    \item Adequate power supply decoupling
    \item Signal line protection and isolation
    \item Modular connections for easy maintenance
\end{itemize}
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\textwidth]{images/circuit_design.png}
    \caption{Complete Circuit Schematic and Wiring Diagram}
    \label{fig:circuit_design}
\end{figure}
\section{Software Implementation}

\subsection{System Initialization}

The software architecture implements a robust state-machine approach for reliable autonomous operation. The initialization process ensures all components are properly configured before operation begins.

\begin{lstlisting}[caption={System Initialization Code}, label={lst:init}]
void setup() {
    // Motor control pins configuration
    pinMode(mr1, OUTPUT); pinMode(mr2, OUTPUT);
    pinMode(ml1, OUTPUT); pinMode(ml2, OUTPUT);
    pinMode(enA, OUTPUT); pinMode(enB, OUTPUT);
    
    // Sensor pins configuration
    pinMode(leftIR, INPUT); pinMode(rightIR, INPUT);
    pinMode(trigPin, OUTPUT); pinMode(echoPin, INPUT);
    
    // Color sensor configuration
    pinMode(S0, OUTPUT); pinMode(S1, OUTPUT);
    pinMode(S2, OUTPUT); pinMode(S3, OUTPUT);
    pinMode(sensorOut, INPUT);
    pinMode(OE, OUTPUT);
    
    // Set color sensor frequency scaling
    digitalWrite(S0, HIGH);
    digitalWrite(S1, LOW);
    digitalWrite(OE, LOW);
    
    // Initialize serial communication
    Serial.begin(9600);
    Serial.println("Robot Initialization Complete");
    
    // Brief delay for system stabilization
    delay(1000);
}
\end{lstlisting}

\subsection{Global Variables and Constants}

\begin{lstlisting}[caption={Global Variables Declaration}, label={lst:globals}]
// Motor control pins
const int mr1 = 2, mr2 = 3, ml1 = 4, ml2 = 5;
const int enA = 6, enB = 9;

// Sensor pins
const int trigPin = 8, echoPin = 7;
const int leftIR = A0, rightIR = A1;

// Color sensor pins
#define S0 A2
#define S1 A3
#define S2 A4
#define S3 A5
#define sensorOut 11
#define OE 13

// System state variables
float distance = 10;
bool avoidingObstacle = false;
int speedA = 70, speedB = 70;

// Color detection variables
int redFrequency = 0;
int greenFrequency = 0;
int blueFrequency = 0;
\end{lstlisting}

\subsection{Movement Control Functions}

The movement control system provides precise motor control for various navigation scenarios:

\begin{lstlisting}[caption={Basic Movement Functions}, label={lst:movement}]
void moveForward(int speedVal1, int speedVal2) {
    analogWrite(enA, speedVal1);
    analogWrite(enB, speedVal2);
    
    // Left motor forward (compensating for reversed wiring)
    digitalWrite(mr1, LOW);
    digitalWrite(mr2, HIGH);
    
    // Right motor forward
    digitalWrite(ml1, HIGH);
    digitalWrite(ml2, LOW);
}

void moveBackward(int speedVal1, int speedVal2) {
    analogWrite(enA, speedVal1);
    analogWrite(enB, speedVal2);
    
    // Left motor backward
    digitalWrite(mr1, HIGH);
    digitalWrite(mr2, LOW);
    
    // Right motor backward
    digitalWrite(ml1, LOW);
    digitalWrite(ml2, HIGH);
}

void stopMotors() {
    analogWrite(enA, 0);
    analogWrite(enB, 0);
    digitalWrite(mr1, LOW); digitalWrite(mr2, LOW);
    digitalWrite(ml1, LOW); digitalWrite(ml2, LOW);
}

void moveWithTurn(int leftSpeed, int rightSpeed) {
    analogWrite(enA, abs(leftSpeed));
    analogWrite(enB, abs(rightSpeed));
    
    // Left motor direction based on speed sign
    digitalWrite(mr1, leftSpeed >= 0 ? LOW : HIGH);
    digitalWrite(mr2, leftSpeed >= 0 ? HIGH : LOW);
    
    // Right motor direction based on speed sign
    digitalWrite(ml1, rightSpeed >= 0 ? HIGH : LOW);
    digitalWrite(ml2, rightSpeed >= 0 ? LOW : HIGH);
}
\end{lstlisting}

\subsection{Main Control Algorithm}

The main control loop implements a priority-based decision system:

\begin{lstlisting}[caption={Main Control Loop}, label={lst:main}]
void loop() {
    // Read distance sensor
    distance = readUltrasonic();
    
    // Priority 1: Obstacle detection and avoidance
    if (distance > 0 && distance <= 6) {
        Serial.print("Obstacle detected at: ");
        Serial.print(distance);
        Serial.println(" cm");
        
        stopMotors();
        delay(500);
        
        // Perform color detection
        String detectedColor = performColorDetection();
        Serial.print("Color detected: ");
        Serial.println(detectedColor);
        
        // Execute appropriate avoidance strategy
        if (detectedColor == "RED") {
            Serial.println("RED obstacle - Overtaking maneuver");
            handleRedObstacle();
        }
        else if (detectedColor == "BLUE") {
            Serial.println("BLUE obstacle - Push through");
            handleBlueObstacle();
        }
        else {
            Serial.println("Unknown color - Default avoidance");
            handleUnknownObstacle();
        }
        return;
    }
    
    // Priority 2: Line following behavior
    executeLineFollowing();
}
\end{lstlisting}

\subsection{Sensor Reading Functions}

\begin{lstlisting}[caption={Ultrasonic Distance Measurement}, label={lst:ultrasonic}]
long readUltrasonic() {
    // Clear trigger pin
    digitalWrite(trigPin, LOW);
    delayMicroseconds(2);
    
    // Send 10 microsecond pulse
    digitalWrite(trigPin, HIGH);
    delayMicroseconds(10);
    digitalWrite(trigPin, LOW);
    
    // Read echo with timeout protection
    long duration = pulseIn(echoPin, HIGH, 20000);
    
    // Check for valid reading
    if (duration == 0) return -1;
    
    // Calculate distance in centimeters
    long distance = duration * 0.034 / 2;
    
    // Validate range
    if (distance > 300 || distance <= 0) return -1;
    
    return distance;
}
\end{lstlisting}

\subsection{Color Detection System}

The color detection algorithm uses statistical analysis for improved accuracy:

\begin{lstlisting}[caption={Color Detection with Statistical Analysis}, label={lst:color}]
String performColorDetection() {
    Serial.println("Performing color analysis...");
    
    // Color counters for statistical analysis
    int redCount = 0, greenCount = 0, blueCount = 0, unknownCount = 0;
    
    // Take multiple readings for reliability
    for (int i = 0; i < 10; i++) {
        String color = readSingleColor();
        
        // Update counters
        if (color == "RED") redCount++;
        else if (color == "GREEN") greenCount++;
        else if (color == "BLUE") blueCount++;
        else unknownCount++;
        
        delay(200);
    }
    
    // Print results
    Serial.print("Color analysis - Red: "); Serial.print(redCount);
    Serial.print(", Green: "); Serial.print(greenCount);
    Serial.print(", Blue: "); Serial.print(blueCount);
    Serial.print(", Unknown: "); Serial.println(unknownCount);
    
    // Majority voting decision
    if (redCount >= 3 && redCount >= greenCount && redCount >= blueCount) {
        return "RED";
    }
    else if (greenCount >= 3 && greenCount >= redCount && greenCount >= blueCount) {
        return "GREEN";
    }
    else if (blueCount >= 3 && blueCount >= redCount && blueCount >= greenCount) {
        return "BLUE";
    }
    else {
        return "UNKNOWN";
    }
}

String readSingleColor() {
    // Read Red frequency
    digitalWrite(S2, LOW); digitalWrite(S3, LOW);
    redFrequency = pulseIn(sensorOut, LOW);
    delay(50);
    
    // Read Green frequency
    digitalWrite(S2, HIGH); digitalWrite(S3, HIGH);
    greenFrequency = pulseIn(sensorOut, LOW);
    delay(50);
    
    // Read Blue frequency
    digitalWrite(S2, LOW); digitalWrite(S3, HIGH);
    blueFrequency = pulseIn(sensorOut, LOW);
    delay(50);
    
    return classifyColor();
}
\end{lstlisting}

\section{Obstacle Handling Strategies}

\subsection{Red Obstacle Avoidance}

For red obstacles, the robot performs a sophisticated overtaking maneuver:

\begin{lstlisting}[caption={Red Obstacle Handling}, label={lst:red_obstacle}]
void handleRedObstacle() {
    Serial.println("Executing red obstacle avoidance...");
    
    // Step 1: Back up slightly
    moveBackward(80, 80);
    delay(500);
    stopMotors();
    delay(300);
    
    // Step 2: Turn left to avoid obstacle
    moveWithTurn(-180, 180);
    delay(400);
    stopMotors();
    delay(300);
    
    // Step 3: Move forward to clear obstacle
    moveForward(70, 70);
    delay(1600);
    stopMotors();
    delay(300);
    
    // Step 4: Turn right to realign with path
    moveWithTurn(200, -200);
    delay(350);
    stopMotors();
    delay(300);
    
    // Step 5: Search for line
    searchForLine();
    
    Serial.println("Red obstacle avoidance complete");
}
\end{lstlisting}

\subsection{Blue Obstacle Handling}

For blue obstacles, the robot attempts to push through:

\begin{lstlisting}[caption={Blue Obstacle Handling}, label={lst:blue_obstacle}]
void handleBlueObstacle() {
    Serial.println("Attempting to push blue obstacle...");
    
    // Apply forward force to push obstacle
    moveForward(100, 100);
    delay(800);
    stopMotors();
    delay(300);
    
    // Return to original position
    moveBackward(100, 100);
    delay(800);
    stopMotors();
    delay(300);
    
    Serial.println("Blue obstacle handling complete");
}
\end{lstlisting}

\section{System Operation and Testing}

\subsection{Operational Modes}

The robot system operates in five distinct modes, each optimized for specific scenarios:

\begin{enumerate}
    \item \textbf{Initialization Mode}: System startup and sensor calibration
    \item \textbf{Line Following Mode}: Primary autonomous navigation
    \item \textbf{Obstacle Detection Mode}: Triggered when objects detected within 6cm
    \item \textbf{Color Analysis Mode}: Activated upon obstacle detection
    \item \textbf{Obstacle Avoidance Mode}: Adaptive response based on color classification
\end{enumerate}

\subsection{Performance Metrics}

Comprehensive testing revealed the following performance characteristics:

\begin{table}[H]
\centering
\begin{tabular}{@{}lr@{}}
\toprule
\textbf{Performance Metric} & \textbf{Measured Value} \\
\midrule
Line Following Accuracy & $> 95\%$ path adherence \\
Obstacle Detection Range & 2-15 cm reliable detection \\
Color Classification Accuracy & 70\% with 10-sample voting \\
Obstacle Detection Response Time & $< 100$ ms \\
Avoidance Maneuver Recovery Time & $< 2$ seconds \\
Battery Life & 45-60 minutes continuous operation \\
Maximum Speed & 15 cm/s forward movement \\
Minimum Turn Radius & 20 cm differential steering \\
\bottomrule
\end{tabular}
\caption{System Performance Metrics}
\label{tab:performance}
\end{table}

\subsection{System Validation}

The system underwent rigorous validation testing across multiple scenarios:

\begin{itemize}
    \item \textbf{Line Following Tests}: Various line configurations and lighting conditions
    \item \textbf{Obstacle Avoidance Tests}: Different obstacle sizes, colors, and positions
    \item \textbf{Color Detection Tests}: Multiple object colors under varying illumination
    \item \textbf{Integration Tests}: Combined functionality scenarios
    \item \textbf{Stress Tests}: Extended operation and edge case handling
\end{itemize}

\section{Behavioral Analysis}

\subsection{Line Following Behavior}

The line following algorithm demonstrates robust performance through a simple but effective decision matrix:

\begin{table}[H]
\centering
\begin{tabular}{@{}ccl@{}}
\toprule
\textbf{Left IR} & \textbf{Right IR} & \textbf{Action} \\
\midrule
0 (on line) & 0 (on line) & Move straight forward \\
0 (on line) & 1 (off line) & Turn right to correct path \\
1 (off line) & 0 (on line) & Turn left to correct path \\
1 (off line) & 1 (off line) & Stop and search for line \\
\bottomrule
\end{tabular}
\caption{Line Following Decision Matrix}
\label{tab:line_following}
\end{table}

\subsection{Obstacle Avoidance Analysis}

The dual-strategy approach for obstacle handling provides adaptive behavior:

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{images/obstacle_avoidance_demo.jpg}
    \caption{Robot demonstrating obstacle avoidance maneuver with color-coded obstacles}
    \label{fig:obstacle_avoidance_demo}
\end{figure}

\textbf{Red Obstacle Strategy Analysis:}
\begin{itemize}
    \item Success rate: 85\% successful navigation around obstacles
    \item Average completion time: 8-12 seconds
    \item Line reacquisition success: 90\%
    \item Suitable for: Fragile or immovable obstacles
\end{itemize}

\textbf{Blue Obstacle Strategy Analysis:}
\begin{itemize}
    \item Success rate: 75\% successful obstacle displacement
    \item Average completion time: 3-5 seconds
    \item Obstacle displacement distance: 5-10 cm
    \item Suitable for: Lightweight, movable obstacles
\end{itemize}

\section{Git Usage and Collaboration}

The development process utilized version control for effective team collaboration:

\begin{table}[H]
\centering
\small
\begin{tabular}{@{}p{3.5cm}rp{6cm}@{}}
\toprule
\textbf{Team Member} & \textbf{Commits} & \textbf{Primary Contribution}\\
\midrule
Md Helal Uddin & 65 & Software implementation, SysML Diagram (6), Presentation, Circuit Design \\
Md Zulkar Nain Sayeed & 16 & Design (2 parts), SysML Diagram (2), Uppaal Simulation, LaTeX Report Creation \\
Md Arman Zaid Efty & 10 & Design (2 parts), SysML Diagram (1)\\
\midrule
\textbf{Total} & \textbf{91} & \\
\bottomrule
\end{tabular}
\caption{Development Contribution Summary}
\label{tab:git_stats}
\end{table}


\section{Conclusion}

This project successfully demonstrates the design and implementation of an intelligent line-following robot with advanced obstacle avoidance capabilities. The system effectively integrates multiple sensor modalities and implements adaptive behavior based on environmental conditions through color-based obstacle classification.

\subsection{Key Achievements}

\begin{itemize}
    \item \textbf{Multi-sensor Integration}: Successful fusion of IR, ultrasonic, and color sensors
    \item \textbf{Adaptive Behavior}: Color-based decision making for obstacle handling
    \item \textbf{Robust Performance}: Reliable operation across diverse test scenarios
    \item \textbf{Modular Design}: Scalable architecture for future enhancements
\end{itemize}

\subsection{Technical Contributions}

The project provides several technical contributions to the field of autonomous robotics:

\begin{itemize}
    \item Novel color-based obstacle classification approach
    \item Statistical voting algorithm for improved sensor reliability
    \item Dual-strategy obstacle avoidance system
    \item Comprehensive real-time sensor processing framework
\end{itemize}

\subsection{Future Work}

Potential enhancements for future development include:

\begin{itemize}
    \item Machine learning integration for improved color recognition
    \item Additional sensor modalities (cameras, LIDAR)
    \item Wireless communication capabilities
    \item Advanced path planning algorithms
    \item Multi-robot coordination and swarm behavior
\end{itemize}

The modular architecture and robust software implementation provide a solid foundation for these future enhancements and applications in autonomous robotics research and education.

\section{References}

\begin{enumerate}
    \item Arduino Foundation. \textit{Arduino Documentation and Programming Guide}. Available: \url{https://www.arduino.cc/en/Guide}
    
    \item Autodesk Inc. \textit{Tinkercad Circuit Simulation Platform}. Available: \url{https://www.tinkercad.com}
    
    \item Uppaal Team. \textit{Uppaal Model Checker for Real-Time Systems}. Available: \url{http://www.uppaal.org/}
    
    \item Siegwart, R., \& Nourbakhsh, I. R. (2004). \textit{Introduction to Autonomous Mobile Robots}. MIT Press, Cambridge, MA.
    
    \item Dudek, G., \& Jenkin, M. (2010). \textit{Computational Principles of Mobile Robotics}. 2nd ed., Cambridge University Press.
    
    \item Murphy, R. R. (2019). \textit{Introduction to AI Robotics}. 2nd ed., MIT Press.
    
    \item Corke, P. (2017). \textit{Robotics, Vision and Control: Fundamental Algorithms in MATLAB}. 2nd ed., Springer.
    
    \item Thrun, S., Burgard, W., \& Fox, D. (2005). \textit{Probabilistic Robotics}. MIT Press.
\end{enumerate}

\vspace{1cm}

\section*{Declaration of Originality}

We hereby declare that this report represents our original work and that all sources used have been properly acknowledged. The software implementation, hardware design, and experimental results presented are the product of our collaborative effort under the guidance of our academic supervisors.



\end{document}